{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"yarn\")\\\n",
    ".config('spark.executor.cores', '2')\\\n",
    ".config('spark.executor.memory', '9G')\\\n",
    ".config('spark.executor.instances','4')\\\n",
    ".appName('bdse62')\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract=spark.read.csv('hdfs:///bdse71/ABS',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = spark.read.json('hdfs:///data/df_mono_ipc.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------+--------+\n",
      "|              Agents|          Applicants|Application_Number|   Designated_States|           Inventors|  PublicationNo_Name|Publication_Date|Publication_Number|               Title|ipc_simplified|mono_ipc|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------+--------+\n",
      "|'ОСИПОВА, Наталья...|[' [CY]/[CY] (All...| PCT/IB2011/002779|[[BF,  BJ,  CF,  ...|'ЯСНЕЦОВ, Владими...|1. WO2012028965 -...|      08-03-2012|    WO/2012/028965|[EN), COMBINATION...|           [A]|       A|\n",
      "|                 nan|[' [BY]/[BY] (AM,...| PCT/BY2015/000005|[[BF,  BJ,  CF,  ...|'ЖАВНЕРКО, Геннад...|1. WO2017070769 -...|      04-05-2017|    WO/2017/070769|[EN), COMPOSITE O...|        [C, G]|       C|\n",
      "|                 nan|[' [BY]/[BY] (AM,...| PCT/BY2015/000005|[[BF,  BJ,  CF,  ...|'ЖАВНЕРКО, Геннад...|1. WO2017070769 -...|      04-05-2017|    WO/2017/070769|[EN), COMPOSITE O...|        [C, G]|       G|\n",
      "|\"ООО 'MEЖДУНAРOДН...|[' [RU]/[RU] (All...| PCT/EA2007/000006|[[BF,  BJ,  CF,  ...|'ТАХАУТДИНОВ Шафа...|1. WO2008046426 -...|      24-04-2008|    WO/2008/046426|[EN), METHOD FOR ...|           [B]|       B|\n",
      "|                 nan|[' [AZ]/[AZ]': 'Б...| PCT/AZ2017/000007|[[BF,  BJ,  CF,  ...|'АЛЫЕВ, Абульфат ...|1. WO2019056075 -...|      28-03-2019|    WO/2019/056075|[EN), METHOD FOR ...|        [C, G]|       C|\n",
      "|                 nan|[' [AZ]/[AZ]': 'Б...| PCT/AZ2017/000007|[[BF,  BJ,  CF,  ...|'АЛЫЕВ, Абульфат ...|1. WO2019056075 -...|      28-03-2019|    WO/2019/056075|[EN), METHOD FOR ...|        [C, G]|       G|\n",
      "|'BENEDETTO, Marco...|[' [IT]/[IT]': 'C...| PCT/IB2015/056276|[[BF,  BJ,  CF,  ...|'MOGNA, Giovanni'...|1. WO2016027231 -...|      25-02-2016|    WO/2016/027231|[EN), METHOD FOR ...|           [A]|       A|\n",
      "|                 nan|[' [BY]/[BY] (AL,...| PCT/BY2014/000007|[[BF,  BJ,  CF,  ...|'ШИРИПОВ, Владими...|1. WO2016033674 -...|      10-03-2016|    WO/2016/033674|[EN), DEVICE FOR ...|           [B]|       B|\n",
      "|                 nan|[' [US]/[US] (All...| PCT/IB2009/050270|[[BF,  BJ,  CF,  ...|'ИВАЩЕНКО Андрей ...|1. WO2009093206 -...|      30-07-2009|    WO/2009/093206|[EN), 3-SULFONYL-...|        [C, A]|       C|\n",
      "|                 nan|[' [US]/[US] (All...| PCT/IB2009/050270|[[BF,  BJ,  CF,  ...|'ИВАЩЕНКО Андрей ...|1. WO2009093206 -...|      30-07-2009|    WO/2009/093206|[EN), 3-SULFONYL-...|        [C, A]|       A|\n",
      "|                 nan|[' [DE]/[DE] (All...| PCT/EP2011/062178|[[BF,  BJ,  CF,  ...|'FISCHER, Rüdiger...|1. WO2012010525 -...|      26-01-2012|    WO/2012/010525|[DE), VERWENDUNG ...|           [A]|       A|\n",
      "|                 nan|[' [AZ]/[AZ] (All...| PCT/AZ2008/000002|[[BF,  BJ,  CF,  ...|'ГАШИМОВ, Ариф Ма...|1. WO2009105840 -...|      03-09-2009|    WO/2009/105840|[EN), METHOD FOR ...|           [H]|       H|\n",
      "|'HOFFMANN EITLE S...|[' [IT]/[IT]': 'A...| PCT/IB2018/058051|[[BF,  BJ,  CF,  ...|  'FERRARI, Alessio'|1. WO2019077521 -...|      25-04-2019|    WO/2019/077521|[EN), LIQUID COMP...|           [A]|       A|\n",
      "|'БАЗАНОВ, Юрий Бо...|[' [RU]/[RU]': 'О...| PCT/IB2015/050897|[[BF,  BJ,  CF,  ...|'ЕРИМБЕТОВ, Кенес...|1. WO2015118488 -...|      13-08-2015|    WO/2015/118488|[EN), AGENT FOR T...|           [A]|       A|\n",
      "|'DR. LASSE WEINMA...|[' [DE]/[DE]': 'J...| PCT/EP2016/072524|[[BF,  BJ,  CF,  ...|'HUDECEK, Michael...|1. WO2017050884 -...|      30-03-2017|    WO/2017/050884|[EN), A METHOD FO...|        [C, A]|       C|\n",
      "|'DR. LASSE WEINMA...|[' [DE]/[DE]': 'J...| PCT/EP2016/072524|[[BF,  BJ,  CF,  ...|'HUDECEK, Michael...|1. WO2017050884 -...|      30-03-2017|    WO/2017/050884|[EN), A METHOD FO...|        [C, A]|       A|\n",
      "|'ФЕДОРОВ, Дмитрий...|[' [RU]/[RU] (All...| PCT/IB2012/052483|[[BF,  BJ,  CF,  ...|'ШУРИГИН, Михаил ...|1. WO2012156938 -...|      22-11-2012|    WO/2012/156938|[EN), COMPOUNDS P...|        [C, A]|       C|\n",
      "|'ФЕДОРОВ, Дмитрий...|[' [RU]/[RU] (All...| PCT/IB2012/052483|[[BF,  BJ,  CF,  ...|'ШУРИГИН, Михаил ...|1. WO2012156938 -...|      22-11-2012|    WO/2012/156938|[EN), COMPOUNDS P...|        [C, A]|       A|\n",
      "|'ASTRAZENECA INTE...|[' [SE]/[SE] (AE,...| PCT/GB2010/050822|[[BF,  BJ,  CF,  ...|'BENNETT, Nichola...|1. WO2010133882 -...|      25-11-2010|    WO/2010/133882|[EN), DISACCHARIN...|        [C, A]|       C|\n",
      "|'ASTRAZENECA INTE...|[' [SE]/[SE] (AE,...| PCT/GB2010/050822|[[BF,  BJ,  CF,  ...|'BENNETT, Nichola...|1. WO2010133882 -...|      25-11-2010|    WO/2010/133882|[EN), DISACCHARIN...|        [C, A]|       A|\n",
      "+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+----------------+------------------+--------------------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|              _c0|                 _c1|\n",
      "+-----------------+--------------------+\n",
      "|PCT/EP2001/009832|Liquid crystal mi...|\n",
      "|PCT/KR2000/000814|The present inven...|\n",
      "|PCT/IL2000/000667|The present inven...|\n",
      "|PCT/DK2001/000750|The invention rel...|\n",
      "|PCT/EP2001/012972|The invention rel...|\n",
      "|PCT/GB1992/000681|Compounds having ...|\n",
      "|PCT/EP2007/000257|The invention rel...|\n",
      "|PCT/GB1992/001189|Compounds of gene...|\n",
      "|PCT/US2001/024105|The present inven...|\n",
      "|PCT/RU2001/000190|The inventive met...|\n",
      "|PCT/EP2004/007957|The invention rel...|\n",
      "|PCT/IL2000/000459|The present inven...|\n",
      "|PCT/KR2006/002440|A diagnostic kit ...|\n",
      "|PCT/KR2001/001941|The present inven...|\n",
      "|PCT/SE2002/000250|To facilitate eg ...|\n",
      "|PCT/GR1993/000005|A technique for t...|\n",
      "|PCT/DE2001/001579|The invention rel...|\n",
      "|PCT/IL2001/000088|A method and circ...|\n",
      "|PCT/KR2001/000965|A preferable embo...|\n",
      "|PCT/GB2001/002487|New spisulosine d...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abstract.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinExpression = testDF['Application_Number']==abstract[\"_c0\"]\n",
    "joinType = \"inner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+--------------------+\n",
      "|Application_Number|mono_ipc|                 _c1|\n",
      "+------------------+--------+--------------------+\n",
      "| PCT/AT2002/000007|       B|The invention rel...|\n",
      "| PCT/AU2001/001240|       A|An electrode asse...|\n",
      "| PCT/CH2000/000616|       A|The invention rel...|\n",
      "| PCT/DE2001/002185|       G|The invention rel...|\n",
      "| PCT/DE2001/003336|       G|According to the ...|\n",
      "| PCT/DE2001/003917|       H|The invention rel...|\n",
      "| PCT/EP2001/003772|       C|The invention rel...|\n",
      "| PCT/EP2001/004360|       C|A method for dete...|\n",
      "| PCT/EP2001/005589|       F|With a view to ra...|\n",
      "| PCT/EP2001/005723|       C|The invention rel...|\n",
      "| PCT/EP2001/005780|       H|The invention rel...|\n",
      "| PCT/EP2001/005780|       C|The invention rel...|\n",
      "| PCT/FI1992/000106|       B|The invention con...|\n",
      "| PCT/FI2001/000982|       C|This invention re...|\n",
      "| PCT/FR2000/002789|       C|The invention rel...|\n",
      "| PCT/FR2000/002789|       A|The invention rel...|\n",
      "| PCT/IB2001/000244|       C|The present inven...|\n",
      "| PCT/IB2001/001581|       C|The present inven...|\n",
      "| PCT/IB2001/001581|       A|The present inven...|\n",
      "| PCT/IL2000/000357|       G|Methods of creati...|\n",
      "+------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF=testDF.join(abstract,joinExpression,joinType).select('Application_Number','mono_ipc','_c1')\n",
    "joinedDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"_c1\", outputCol=\"words\",pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"removededWords\") # stopWords=yourownstopwords\n",
    "vectorizer = CountVectorizer(inputCol=\"removededWords\", outputCol=\"rawFeatures\")\n",
    "#idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\") # minDocFreq=2, TF小於2的就忽略\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2)\n",
    "pipeline = Pipeline(stages=[tokenizer,remover ,vectorizer, idf])\n",
    "model = pipeline.fit(joinedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "| vocabList|counts|\n",
      "+----------+------+\n",
      "| invention|3814.0|\n",
      "|      said|2590.0|\n",
      "|       one|2459.0|\n",
      "|     least|2110.0|\n",
      "|   relates|2055.0|\n",
      "|    method|1878.0|\n",
      "|comprising|1672.0|\n",
      "|    device|1404.0|\n",
      "|     means|1352.0|\n",
      "|     first|1122.0|\n",
      "| comprises|1108.0|\n",
      "|       use|1055.0|\n",
      "|   surface|1048.0|\n",
      "|      also|1035.0|\n",
      "|  material|1004.0|\n",
      "|    system|1003.0|\n",
      "|    second| 981.0|\n",
      "|  provided| 960.0|\n",
      "|   present| 930.0|\n",
      "|   wherein| 906.0|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "total_counts = model.transform(joinedDF).select('rawFeatures').rdd.map(lambda row: row['rawFeatures'].toArray()).reduce(lambda x,y: [x[i]+y[i] for i in range(len(y))])\n",
    "vocabList = model.stages[2].vocabulary\n",
    "d = {'vocabList':vocabList,'counts':total_counts}\n",
    "spark.createDataFrame(np.array(list(d.values())).T.tolist(),list(d.keys())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=model.transform(joinedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    4548|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf.createOrReplaceTempView(\"table1\")\n",
    "spark.sql('select count(*) from table1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Application_Number',\n",
       " 'mono_ipc',\n",
       " '_c1',\n",
       " 'words',\n",
       " 'removededWords',\n",
       " 'rawFeatures',\n",
       " 'features']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfForTrain=spark.sql('select mono_ipc,rawFeatures, features from table1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|mono_ipc|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+\n",
      "|       B|(18778,[0,3,4,6,7...|(18778,[0,3,4,6,7...|\n",
      "|       A|(18778,[6,30,104,...|(18778,[6,30,104,...|\n",
      "|       A|(18778,[0,3,4,5,1...|(18778,[0,3,4,5,1...|\n",
      "|       G|(18778,[0,4,5,13,...|(18778,[0,4,5,13,...|\n",
      "|       G|(18778,[0,1,7,14,...|(18778,[0,1,7,14,...|\n",
      "|       H|(18778,[0,3,4,5,8...|(18778,[0,3,4,5,8...|\n",
      "|       C|(18778,[0,1,4,5,2...|(18778,[0,1,4,5,2...|\n",
      "|       C|(18778,[5,6,9,16,...|(18778,[5,6,9,16,...|\n",
      "|       F|(18778,[1,17,64,8...|(18778,[1,17,64,8...|\n",
      "|       C|(18778,[0,2,4,19,...|(18778,[0,2,4,19,...|\n",
      "|       H|(18778,[0,2,3,4,5...|(18778,[0,2,3,4,5...|\n",
      "|       C|(18778,[0,2,3,4,5...|(18778,[0,2,3,4,5...|\n",
      "|       B|(18778,[0,1,6,8,4...|(18778,[0,1,6,8,4...|\n",
      "|       C|(18778,[0,4,5,14,...|(18778,[0,4,5,14,...|\n",
      "|       C|(18778,[0,2,3,4,6...|(18778,[0,2,3,4,6...|\n",
      "|       A|(18778,[0,2,3,4,6...|(18778,[0,2,3,4,6...|\n",
      "|       C|(18778,[0,4,13,18...|(18778,[0,4,13,18...|\n",
      "|       C|(18778,[0,1,4,5,6...|(18778,[0,1,4,5,6...|\n",
      "|       A|(18778,[0,1,4,5,6...|(18778,[0,1,4,5,6...|\n",
      "|       G|(18778,[2,3,5,12,...|(18778,[2,3,5,12,...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfForTrain.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors # !!!!caution: not from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IndexToString,StringIndexer, VectorIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+------------+\n",
      "|mono_ipc|         rawFeatures|            features|indexedLabel|\n",
      "+--------+--------------------+--------------------+------------+\n",
      "|       B|(18778,[0,3,4,6,7...|(18778,[0,3,4,6,7...|         2.0|\n",
      "|       A|(18778,[6,30,104,...|(18778,[6,30,104,...|         0.0|\n",
      "|       A|(18778,[0,3,4,5,1...|(18778,[0,3,4,5,1...|         0.0|\n",
      "|       G|(18778,[0,4,5,13,...|(18778,[0,4,5,13,...|         3.0|\n",
      "|       G|(18778,[0,1,7,14,...|(18778,[0,1,7,14,...|         3.0|\n",
      "+--------+--------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelIndexer = StringIndexer(inputCol='mono_ipc',outputCol='indexedLabel').fit(tfidfForTrain)\n",
    "labelIndexer.transform(tfidfForTrain).show(5, True)\n",
    "stage1=labelIndexer.transform(tfidfForTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = stage1.randomSplit([0.6, 0.4])\n",
    "#trainingData.show(2,truncate=False)\n",
    "#testData.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(featuresCol='features', labelCol='indexedLabel')\n",
    "stage2=logr.fit(trainingData).transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+------------+--------------------+--------------------+----------+\n",
      "|mono_ipc|         rawFeatures|            features|indexedLabel|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+--------------------+------------+--------------------+--------------------+----------+\n",
      "|       A|(18778,[0,2,3,4,6...|(18778,[0,2,3,4,6...|         0.0|[-104.76359778962...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|       A|(18778,[6,30,104,...|(18778,[6,30,104,...|         0.0|[-30.771753986580...|[9.68753173195840...|       4.0|\n",
      "|       B|(18778,[0,3,4,6,7...|(18778,[0,3,4,6,7...|         2.0|[-44.143478410535...|[8.36028938053069...|       6.0|\n",
      "|       G|(18778,[0,4,5,13,...|(18778,[0,4,5,13,...|         3.0|[-591.92806829425...|[0.0,1.0,0.0,1.41...|       1.0|\n",
      "|       H|(18778,[0,2,3,4,5...|(18778,[0,2,3,4,5...|         4.0|[-128.38596039992...|[0.0,1.0,6.126823...|       1.0|\n",
      "|       A|(18778,[0,2,10,12...|(18778,[0,2,10,12...|         0.0|[123.477958694314...|[1.0,1.3851310503...|       0.0|\n",
      "|       A|(18778,[0,4,10,22...|(18778,[0,4,10,22...|         0.0|[-64.171678946210...|[1.04878786001143...|       2.0|\n",
      "|       A|(18778,[0,4,13,18...|(18778,[0,4,13,18...|         0.0|[-103.12443197521...|[9.19483065458986...|       1.0|\n",
      "|       A|(18778,[0,29,35,3...|(18778,[0,29,35,3...|         0.0|[-64.812648897485...|[5.62490008980729...|       1.0|\n",
      "|       B|(18778,[0,1,2,4,1...|(18778,[0,1,2,4,1...|         2.0|[362.210024830556...|[0.50166976777357...|       0.0|\n",
      "|       C|(18778,[0,1,4,19,...|(18778,[0,1,4,19,...|         1.0|[260.589861064609...|[1.36651082401933...|       1.0|\n",
      "|       C|(18778,[1,5,6,10,...|(18778,[1,5,6,10,...|         1.0|[-237.93966907686...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|       C|(18778,[1,21,27,4...|(18778,[1,21,27,4...|         1.0|[442.683092368988...|[1.0,1.5864390454...|       0.0|\n",
      "|       H|(18778,[2,5,11,13...|(18778,[2,5,11,13...|         4.0|[-287.82276444534...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|       A|(18778,[0,4,6,7,8...|(18778,[0,4,6,7,8...|         0.0|[617.470316544188...|[1.0,0.0,4.026423...|       0.0|\n",
      "|       A|(18778,[6,14,25,2...|(18778,[6,14,25,2...|         0.0|[527.002157581215...|[1.0,0.0,5.405655...|       0.0|\n",
      "|       A|(18778,[12,13,17,...|(18778,[12,13,17,...|         0.0|[446.542771845157...|[1.0,0.0,6.030050...|       0.0|\n",
      "|       B|(18778,[0,1,4,5,1...|(18778,[0,1,4,5,1...|         2.0|[-75.970922642582...|[1.98575288057063...|       1.0|\n",
      "|       B|(18778,[1,2,8,24,...|(18778,[1,2,8,24,...|         2.0|[-437.05160358736...|[0.0,4.9343454593...|       2.0|\n",
      "|       B|(18778,[33,67,74,...|(18778,[33,67,74,...|         2.0|[-122.15498839713...|[1.57253193804042...|       1.0|\n",
      "+--------+--------------------+--------------------+------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------+\n",
      "|            features|mono_ipc|predictedLabel|\n",
      "+--------------------+--------+--------------+\n",
      "|(18778,[0,2,3,4,6...|       A|             C|\n",
      "|(18778,[6,30,104,...|       A|             H|\n",
      "|(18778,[0,3,4,6,7...|       B|             E|\n",
      "|(18778,[0,4,5,13,...|       G|             C|\n",
      "|(18778,[0,2,3,4,5...|       H|             C|\n",
      "|(18778,[0,2,10,12...|       A|             A|\n",
      "|(18778,[0,4,10,22...|       A|             B|\n",
      "|(18778,[0,4,13,18...|       A|             C|\n",
      "|(18778,[0,29,35,3...|       A|             C|\n",
      "|(18778,[0,1,2,4,1...|       B|             A|\n",
      "|(18778,[0,1,4,19,...|       C|             C|\n",
      "|(18778,[1,5,6,10,...|       C|             C|\n",
      "|(18778,[1,21,27,4...|       C|             A|\n",
      "|(18778,[2,5,11,13...|       H|             H|\n",
      "|(18778,[0,4,6,7,8...|       A|             A|\n",
      "|(18778,[6,14,25,2...|       A|             A|\n",
      "|(18778,[12,13,17,...|       A|             A|\n",
      "|(18778,[0,1,4,5,1...|       B|             C|\n",
      "|(18778,[1,2,8,24,...|       B|             B|\n",
      "|(18778,[33,67,74,...|       B|             C|\n",
      "+--------------------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",labels=labelIndexer.labels)\n",
    "labelConverter.transform(stage2).select('features','mono_ipc','predictedLabel').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\")\n",
    "labelConverter.transform(stage2).select('indexedLabel','prediction').createOrReplaceTempView('table1')\n",
    "predictionAndTarget = spark.sql('select indexedLabel as label, prediction from table1')\n",
    "acc = evaluator.evaluate(predictionAndTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4359177129475953\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c6b4d5d9db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
